{"cells":[{"cell_type":"markdown","metadata":{"id":"KY4js3aX7no6"},"source":["# **PROJECT 1 - OBJECT DETECTION IN URBAN ENVIRONMENT**\n"]},{"cell_type":"markdown","metadata":{"id":"ORo9oGPiA8k7"},"source":["## **ROADMAP**\n","\n","\n","* Install the TensorFlow Object Detection API.\n","\n","* Edit the model pipeline config file and download the pre-trained model checkpoint.\n","\n","* Train and evaluate the model.\n","\n","* Output a video with detections\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pjfRnVN12JWF"},"source":["# **1) Import Libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9443,"status":"ok","timestamp":1680555435869,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"R1Fl0K9TVJ50","outputId":"f391c16e-4052-4b0b-8b7c-a95825ecf352","vscode":{"languageId":"python"}},"outputs":[],"source":["import os\n","import glob\n","import xml.etree.ElementTree as ET\n","import pandas as pd\n","import tensorflow as tf\n","print(tf.__version__)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OLsPGJiuxRrK"},"source":["# **2) Mount drive and link your folder**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25176,"status":"ok","timestamp":1680555465991,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"RhZoiRBoqnju","outputId":"68d86719-0f9c-4107-e7dd-8dd1a321c7bc","vscode":{"languageId":"python"}},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive\n","!ls /mydrive"]},{"cell_type":"markdown","metadata":{"id":"useG4r6nOn9h"},"source":["# **3) Clone the tensorflow models git repository & Install TensorFlow Object Detection API**\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77652,"status":"ok","timestamp":1680555546887,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"Iv3C8-s0koQU","outputId":"e3794426-de2f-4a2a-9219-95c361c09750","vscode":{"languageId":"python"}},"outputs":[],"source":["# clone the tensorflow models on the colab cloud vm\n","!git clone --q https://github.com/tensorflow/models.git\n","\n","#navigate to /models/research folder to compile protos\n","%cd models/research\n","\n","# Compile protos.\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","# Install TensorFlow Object Detection API.\n","!cp object_detection/packages/tf2/setup.py .\n","!python -m pip install .\n"]},{"cell_type":"markdown","metadata":{"id":"9D1UNW7c9O-I"},"source":["# **4) Test the model builder**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87166,"status":"ok","timestamp":1680555640147,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"St1r_0-w9jqI","outputId":"69a496fd-d9cc-445d-f55b-da1befffdb04","vscode":{"languageId":"python"}},"outputs":[],"source":["# Testing the model builder\n","!python object_detection/builders/model_builder_tf2_test.py"]},{"cell_type":"markdown","metadata":{"id":"nwWh49ClaBeD"},"source":["# **5) Download pre-trained model checkpoint** \n","\n","Download **the model** into the **data** folder & unzip it.\n","\n","A list of detection checkpoints for tensorflow 2.x can be found [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md).\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1680555640150,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"sM1Io0YEp1Nk","outputId":"06301abd-5354-4790-e34e-a0d98d1b9889","vscode":{"languageId":"python"}},"outputs":[],"source":["# Working directory\n","\n","%cd /mydrive/Project/customTF2/data/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4939,"status":"ok","timestamp":1680543813638,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"obEW7RNEcowc","outputId":"4391505c-25fc-45b6-dc82-86b26ec7c7cf","vscode":{"languageId":"python"}},"outputs":[],"source":["#Download the pre-trained model into the data folder & unzip it.\n","\n","# !wget -< Link of the pre-trained model >-\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","\n","!tar -xzvf ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz"]},{"cell_type":"markdown","metadata":{"id":"XS-xqg02X9Ro"},"source":["# **6) Get the model pipeline config file, make changes to it and put it inside the *data* folder**\n","\n","Current working directory is /mydrive/Project/customTF2/data/\n","\n","Download **the model** from ***/content/models/research/object_detection/configs/tf2***. Make the required changes to it and upload it to the ***/mydrive/Project/customTF2/data*** folder.\n","\n","**OR**\n","\n","Edit the config file from ***/content/models/research/object_detection/configs/tf2*** in colab and copy the edited config file to the ***/mydrive/Project/customTF2/data*** folder.\n","\n","You can also find the pipeline config file inside the model checkpoint folder we just downloaded in the previous step.\n","\n","**You need to make the following changes:**\n","*   change ***num_classes*** to number of your classes.\n","*   change ***test.record*** path, ***train.record*** path & ***labelmap*** path to the paths where you have created these files (paths should be relative to your current working directory while training).\n","* change ***fine_tune_checkpoint*** to the path of the directory where the downloaded checkpoint. \n","* change ***fine_tune_checkpoint_type*** with value **classification** or **detection** depending on the type..\n","* change ***batch_size*** to any multiple of 8 depending upon the capability of your GPU.\n","(eg:- 24,128,...,512). \n","* change ***num_steps*** to number of steps you want the detector to train. \n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ze7ewaO3c545","vscode":{"languageId":"python"}},"outputs":[],"source":["#copy the edited config file from the configs/tf2 directory to the data/ folder in your drive\n","\n","!cp /content/models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config /mydrive/Project/customTF2/data"]},{"cell_type":"markdown","metadata":{"id":"88pz7JpMNRRK"},"source":["# **7) Load Tensorboard**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":60817,"status":"ok","timestamp":1680555700958,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"l-86d0AXNQp7","outputId":"293bbd34-40e1-4c6c-dee2-80e8f0eb9c16","vscode":{"languageId":"python"}},"outputs":[],"source":["# Load TensorBoard\n","\n","%load_ext tensorboard\n","%tensorboard --logdir '/content/gdrive/MyDrive/Project/customTF2/logs'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8lq4rGdbXZr","vscode":{"languageId":"python"}},"outputs":[],"source":["## Incase an error occurs with TensorBoard run the following lines to find this session PID and terminate it using !kill\n","\n","# from tensorboard import notebook\n","# notebook.list() # View open TensorBoard instances"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZQ4IMAyArOL","vscode":{"languageId":"python"}},"outputs":[],"source":["# !kill -< PID >-"]},{"cell_type":"markdown","metadata":{"id":"tlzGrIfdAKj9"},"source":["# **8) Train the model** \n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yPmZ2cv17jIj"},"source":["## Navigate to the ***object_detection*** folder in colab vm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1680571499475,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"-40iq_0ZMgfL","outputId":"5001d44f-c95f-409d-fba2-95ee633792fb","vscode":{"languageId":"python"}},"outputs":[],"source":["%cd /content/models/research/object_detection"]},{"cell_type":"markdown","metadata":{"id":"_pjP3TuBMjli"},"source":["## I - Training using model_main_tf2.py\n","\n","Here **{PIPELINE_CONFIG_PATH}** points to the pipeline config and **{MODEL_DIR}** points to the directory in which training checkpoints and events will be written.\n","\n","For best results, you should stop the training when the loss is less than 0.1 if possible, else train the model until the loss does not show any significant change for a while. The ideal loss should be below 0.05 (Try to get the loss as low as possible without overfitting the model. Donâ€™t go too high on training steps to try and lower the loss if the model has already converged viz. if it does not reduce loss significantly any further and takes a while to go down. )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10908,"status":"ok","timestamp":1680571514270,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"7LS0SBCgRuox","outputId":"21766248-84cf-48e2-a0e7-6cd86867997b","vscode":{"languageId":"python"}},"outputs":[],"source":["# Run the command below from the content/models/research/object_detection directory\n","\"\"\"\n","PIPELINE_CONFIG_PATH=path/to/pipeline.config\n","MODEL_DIR=path to training checkpoints directory\n","NUM_TRAIN_STEPS=2000\n","SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n","\n","python model_main_tf2.py -- \\\n","  --model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \\\n","  --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n","  --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n","  --alsologtostderr\n","\"\"\"\n","\n","!python model_main_tf2.py --pipeline_config_path=/mydrive/Project/customTF2/data/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config --model_dir=/mydrive/Project/customTF2/logs/mobilenet_logs --alsologtostderr\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xzZdwx7kgOV1"},"source":["### <u>**TROUBLESHOOTING:**</u> \n","If you get an error for _registerMatType cv2 above, this might be because of OpenCV version mismatches in Colab. Run `!pip list|grep opencv` to see the versions of OpenCV packages installed i.e. `opencv-python`, `opencv-contrib-python` & `opencv-python-headless`. The versions will be different which is causing this error. This error will go away when colab updates it supported versions. For now, you can fix this by simply uninstalling and installing OpenCV packages. \n","\n","**Check versions:**\n","\n","!pip list|grep opencv\n","\n","\n","**Use the following 2 commands if only the opencv-python-headless is of different version**:\n","\n","!pip uninstall opencv-python-headless --y\n","\n","!pip install opencv-python-headless==4.1.2.30\n","\n","\n","**Or use the following commands if other opencv packages are of different versions. Uninstall and install all with the same version**:\n","\n","!pip uninstall opencv-python --y\n","\n","!pip uninstall opencv-contrib-python --y \n","\n","!pip uninstall opencv-python-headless --y\n","\n","\n","!pip install opencv-python==4.5.4.60\n","\n","!pip install opencv-contrib-python==4.5.4.60\n","\n","!pip install opencv-python-headless==4.5.4.60\n"]},{"cell_type":"markdown","metadata":{"id":"2KoZ6zVpDmtT"},"source":["## II - Evaluation using model_main_tf2.py (Optional)\n","\n","You can run this in parallel by opening another colab notebook and running this command simultaneously along with the training command above (don't forget to mount drive, clone the TF git repo and install the TF2 object detection API there as well). This will give you validation loss, mAP, etc so you have a better idea of how your model is performing.\n","\n","Here **{CHECKPOINT_DIR}** points to the directory with checkpoints produced by the training job. Evaluation events are written to **{MODEL_DIR/eval}**. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6099,"status":"ok","timestamp":1680571469336,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"YHAeEbZE_sZ-","outputId":"b9a377a4-c9b8-48c9-ab77-8298cbb1778c","vscode":{"languageId":"python"}},"outputs":[],"source":["# Run the command below from the content/models/research/object_detection directory\n","\"\"\"\n","PIPELINE_CONFIG_PATH=path/to/pipeline.config\n","MODEL_DIR=path to training checkpoints directory\n","CHECKPOINT_DIR=${MODEL_DIR}\n","NUM_TRAIN_STEPS=2000\n","SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n","\n","python model_main_tf2.py -- \\\n","  --model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \\\n","  --checkpoint_dir=${CHECKPOINT_DIR} \\\n","  --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n","  --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n","  --alsologtostderr\n","\"\"\"\n","\n","!python model_main_tf2.py --pipeline_config_path=/mydrive/Project/customTF2/data/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config --model_dir=/mydrive/Project/customTF2/data/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/mobilenet_logs --alsologtostderr\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3-rHe_AzNSs8"},"source":["## RETRAINING THE MODEL ( in case you get disconnected )\n","\n","\n","If you get disconnected or lose your session on colab vm, you can start your training where you left off as the checkpoint is saved on your drive inside the ***training*** folder. To restart the training simply run **steps 1 till 7.**\n","\n","Note that since we have all the files required for training like the record files,our edited pipeline config file,the label_map file and the model checkpoint folder, therefore we do not need to create these again. \n","\n","**The model_main_tf2.py script saves the checkpoint every 1000 steps.** The training automatically restarts from the last saved checkpoint itself.\n","\n","However, if you see that it doesn't restart training from the last checkpoint you can make 1 change in the pipeline config file. Change **fine_tune_checkpoint** to where your latest trained checkpoints have been written and have it point to the latest checkpoint as shown below:\n","\n","\n","``` \n","fine_tune_checkpoint: \"/mydrive/customTF2/training/ckpt-X\" (where ckpt-X is the latest checkpoint)\n","\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"Nxn-FtdtpsTx"},"source":["# **9) Test your trained model**"]},{"cell_type":"markdown","metadata":{"id":"B_tTeYM5ScU1"},"source":["## Export inference graph\n","\n","Current working directory is /content/models/research/object_detection"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227744,"status":"ok","timestamp":1680555945229,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"NB4JHHqHSoiq","outputId":"a21899ca-ceae-472b-f7b5-5a93f396b8e2","vscode":{"languageId":"python"}},"outputs":[],"source":["# Export inference graph\n","\n","!python exporter_main_v2.py --trained_checkpoint_dir=/mydrive/Project/customTF2/logs/ --pipeline_config_path=/mydrive/Project/customTF2/data/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config --output_directory /mydrive/Project/customTF2/data/inference_graph_mobilenet"]},{"cell_type":"markdown","metadata":{"id":"IAol0HB1wkEx"},"source":["## Test your trained Object Detection model on a video\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":578,"status":"ok","timestamp":1680555945800,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"ezrVRRjLenw3","vscode":{"languageId":"python"}},"outputs":[],"source":["# Importing libraries\n","\n","import tensorflow as tf\n","import time\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680555945801,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"8VsULYhnenAY","vscode":{"languageId":"python"}},"outputs":[],"source":["# Output display size as you want\n","\n","IMAGE_SIZE = (12, 8)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20539,"status":"ok","timestamp":1680555993107,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"jSHmdCiy7nP1","outputId":"1cd9c1c2-9bba-4bcb-af7b-ccbd618bdc74","vscode":{"languageId":"python"}},"outputs":[],"source":["# Load the model\n","\n","PATH_TO_SAVED_MODEL=\"/mydrive/Project/customTF2/data/inference_graph/saved_model\"\n","detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","print('Done!')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1680555993111,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"U35TkvI0ecQm","vscode":{"languageId":"python"}},"outputs":[],"source":["category_index = {\n","                    1:{'id': 1, 'name': 'vehicle'}, \n","                    2: {'id': 2, 'name': 'pedestrian'},\n","                    4: {'id': 4, 'name': 'cyclist'}\n","                }"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6579,"status":"ok","timestamp":1680555999679,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"pcvUddC2auGp","vscode":{"languageId":"python"}},"outputs":[],"source":["# Convert each frame into a np array and save it in list 'x'\n","\n","frames_path = sorted(glob.glob('/mydrive/Project/test_video/*.png'), \n","                     key = lambda k: int(os.path.basename(k).split('.')[0].split('_')[1]))\n","\n","x = np.array([np.array(Image.open(fname)) for fname in frames_path])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":432504,"status":"ok","timestamp":1680558626682,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"V5Og_1ZTdV1x","vscode":{"languageId":"python"}},"outputs":[],"source":["# Objects detected on each frame\n","\n","images = []\n","\n","for i in x:\n","\n","  input_tensor = tf.convert_to_tensor(i)\n","  input_tensor = input_tensor[tf.newaxis, ...]\n","\n","  detections = detect_fn(input_tensor)\n","\n","  num_detections = int(detections.pop('num_detections'))\n","\n","  detections = {key: value[0, :num_detections].numpy()\n","                for key, value in detections.items()}\n","  detections['num_detections'] = num_detections\n","\n","  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","  image_np_with_detections = i.copy()\n","\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_detections,\n","      detections['detection_boxes'],\n","      detections['detection_classes'],\n","      detections['detection_scores'],\n","      category_index,\n","      use_normalized_coordinates = True,\n","      max_boxes_to_draw = 200,\n","      min_score_thresh = .3, # Adjust this value to set the minimum probability boxes to be classified as True\n","      agnostic_mode=False)\n","  \n","  images.append(image_np_with_detections)\n","  \n","## The following lines visualize the detections on the image\n","\n","  # %matplotlib inline\n","  # plt.figure(figsize=IMAGE_SIZE, dpi=200)\n","  # plt.axis(\"off\")\n","  # plt.imshow(image_np_with_detections)\n","  # plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23486,"status":"ok","timestamp":1680558650161,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"W9ipaDhmtGxA","vscode":{"languageId":"python"}},"outputs":[],"source":["# Each frame is exported to 'images_new' directory \n","\n","from PIL import Image\n","import numpy as np\n","\n","w = 0\n","\n","for i in images:\n","  img = Image.fromarray(i, \"RGB\")\n","  w = w + 1\n","  img.save('/content/gdrive/MyDrive/Project/images_new/' + str(w) + '.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4097,"status":"ok","timestamp":1680558654249,"user":{"displayName":"A Boo","userId":"10559946147117025056"},"user_tz":-120},"id":"PAzuODm0zn5z","vscode":{"languageId":"python"}},"outputs":[],"source":["#  Frames from 'images_new' directory are converted into a video\n","\n","import numpy as np\n","import glob\n"," \n","img_array = []\n","for filename in glob.glob('/content/gdrive/MyDrive/Project/images_new/*.png'):\n","    img = cv2.imread(filename)\n","    height, width, layers = img.shape\n","    size = (width,height)\n","    img_array.append(img)\n"," \n"," \n","out = cv2.VideoWriter('/content/gdrive/MyDrive/Project/images_new/project.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n"," \n","for i in range(len(img_array)):\n","    out.write(img_array[i])\n","out.release()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1QCU_dCR0ozI8j6X2btEDCsaUk5p_b1uw","timestamp":1680381473827},{"file_id":"12BNAgMHzQ5YgaijYxvVKWkGUtNSq1In3","timestamp":1636485335078},{"file_id":"1YWjDuJgdIvK1yenD3Wmb3_JARuPOuKht","timestamp":1615417926325}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
